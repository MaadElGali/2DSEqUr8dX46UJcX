{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb835989-b373-49b9-a9fb-14c251564ae5",
   "metadata": {},
   "source": [
    "# Background:\n",
    "\n",
    "We are one of the fastest growing startups in the logistics and delivery domain. We work with several partners and make on-demand delivery to our customers. From operational standpoint we have been facing several different challenges and everyday we are trying to address these challenges.\n",
    "\n",
    "We thrive on making our customers happy. As a growing startup, with a global expansion strategy we know that we need to make our customers happy and the only way to do that is to measure how happy each customer is. If we can predict what makes our customers happy or unhappy, we can then take necessary actions.\n",
    "\n",
    "Getting feedback from customers is not easy either, but we do our best to get constant feedback from our customers. This is a crucial function to improve our operations across all levels.\n",
    "\n",
    "We recently did a survey to a select customer cohort. You are presented with a subset of this data. We will be using the remaining data as a private test set.\n",
    "\n",
    "# Data Description:\n",
    "\n",
    "Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers\n",
    "\n",
    "X1 = my order was delivered on time\n",
    "\n",
    "X2 = contents of my order was as I expected\n",
    "\n",
    "X3 = I ordered everything I wanted to order\n",
    "\n",
    "X4 = I paid a good price for my order\n",
    "\n",
    "X5 = I am satisfied with my courier\n",
    "\n",
    "X6 = the app makes ordering easy for me\n",
    "\n",
    "Attributes X1 to X6 indicate the responses for each question and have values from 1 to 5 where the smaller number indicates less and the higher number indicates more towards the answer.\n",
    "\n",
    "# Download Data:\n",
    "\n",
    "https://drive.google.com/open?id=1KWE3J0uU_sFIJnZ74Id3FDBcejELI7FD\n",
    "\n",
    "# Goal(s):\n",
    "\n",
    "Predict if a customer is happy or not based on the answers they give to questions asked.\n",
    "\n",
    "# Success Metrics:\n",
    "\n",
    "Reach 73% accuracy score or above, or convince us why your solution is superior. We are definitely interested in every solution and insight you can provide us.\n",
    "\n",
    "Try to submit your working solution as soon as possible. The sooner the better.\n",
    "\n",
    "# Bonus(es):\n",
    "\n",
    "We are very interested in finding which questions/features are more important when predicting a customer’s happiness. Using a feature selection approach show us understand what is the minimal set of attributes/features that would preserve the most information about the problem while increasing predictability of the data we have. Is there any question that we can remove in our next survey?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838eca7b-cadd-420f-a1cd-1620912ae8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d788cb-fa86-4026-8f7b-a14227f69b7b",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1742aa2a-062e-4458-992e-988af8b75f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Y  X1  X2  X3  X4  X5  X6\n",
      "0  0   3   3   3   4   2   4\n",
      "1  0   3   2   3   5   4   3\n",
      "2  1   5   3   3   3   3   5\n",
      "3  0   5   4   3   3   3   5\n",
      "4  0   5   4   3   3   3   5\n"
     ]
    }
   ],
   "source": [
    "#loading the CSV data\n",
    "\n",
    "customers = pd.read_csv('ACME-HappinessSurvey2020.csv')\n",
    "\n",
    "#looking at the first five rows of the data\n",
    "\n",
    "print(customers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfff2a-1fff-4104-a877-0b213425245e",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6f12a0-4052-4901-980d-bda62b8ecc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y     0\n",
      "X1    0\n",
      "X2    0\n",
      "X3    0\n",
      "X4    0\n",
      "X5    0\n",
      "X6    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#examining if there are any missing values in the data\n",
    "\n",
    "print(customers.isnull().sum())\n",
    "\n",
    "#upon the examination, there are no missing values in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929da2bc-3e6e-4b16-82b7-791d890c7150",
   "metadata": {},
   "source": [
    "# Data Exploration \n",
    "\n",
    "Here is the description of the data\n",
    "\n",
    "Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers\n",
    "\n",
    "X1 = my order was delivered on time\n",
    "\n",
    "X2 = contents of my order was as I expected\n",
    "\n",
    "X3 = I ordered everything I wanted to order\n",
    "\n",
    "X4 = I paid a good price for my order\n",
    "\n",
    "X5 = I am satisfied with my courier\n",
    "\n",
    "X6 = the app makes ordering easy for me\n",
    "\n",
    "Attributes X1 to X6 indicate the responses for each question and have values from 1 to 5 where the smaller number indicates less and the higher number indicates more towards the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6a4c4ac-7fab-460f-81b2-0ed9d7997039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.547619</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.531746</td>\n",
       "      <td>3.309524</td>\n",
       "      <td>3.746032</td>\n",
       "      <td>3.650794</td>\n",
       "      <td>4.253968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499714</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.114892</td>\n",
       "      <td>1.023440</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>1.147641</td>\n",
       "      <td>0.809311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Y          X1          X2          X3          X4          X5  \\\n",
       "count  126.000000  126.000000  126.000000  126.000000  126.000000  126.000000   \n",
       "mean     0.547619    4.333333    2.531746    3.309524    3.746032    3.650794   \n",
       "std      0.499714    0.800000    1.114892    1.023440    0.875776    1.147641   \n",
       "min      0.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000    4.000000    2.000000    3.000000    3.000000    3.000000   \n",
       "50%      1.000000    5.000000    3.000000    3.000000    4.000000    4.000000   \n",
       "75%      1.000000    5.000000    3.000000    4.000000    4.000000    4.000000   \n",
       "max      1.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "               X6  \n",
       "count  126.000000  \n",
       "mean     4.253968  \n",
       "std      0.809311  \n",
       "min      1.000000  \n",
       "25%      4.000000  \n",
       "50%      4.000000  \n",
       "75%      5.000000  \n",
       "max      5.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing quick summary Stats\n",
    "\n",
    "customers.describe()\n",
    "\n",
    "#data has 126 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de49a6ee-6853-4b66-a8ba-b50458430901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy vs Unhappy customers:\n",
      " Y\n",
      "1    69\n",
      "0    57\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#counting the number of happy customers vs. unhappy customers\n",
    "\n",
    "happy_unhappy_counts = customers['Y'].value_counts()\n",
    "print(\"Happy vs Unhappy customers:\\n\", happy_unhappy_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97f384b3-481c-4e0e-9973-1a9ebb568de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings distribution for X1:\n",
      " X1\n",
      "1     1\n",
      "3    20\n",
      "4    40\n",
      "5    65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Happy vs Unhappy in X1:\n",
      " X1    1     3     4     5\n",
      "Y                        \n",
      "0   1.0  12.0  24.0  20.0\n",
      "1   0.0   8.0  16.0  45.0\n"
     ]
    }
   ],
   "source": [
    "#counting the ratings for X1 as well as the number of happy customers vs. unhappy customers\n",
    "\n",
    "ratings_X1 = customers['X1'].value_counts().sort_index()\n",
    "happy_unhappy_X1 = customers.groupby('Y')['X1'].value_counts().unstack().fillna(0)\n",
    "\n",
    "print(\"\\nRatings distribution for X1:\\n\", ratings_X1)\n",
    "print(\"\\nHappy vs Unhappy in X1:\\n\", happy_unhappy_X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6329c56-b55b-4c35-9b16-301c69c08d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings distribution for X2:\n",
      " X2\n",
      "1    27\n",
      "2    34\n",
      "3    42\n",
      "4    17\n",
      "5     6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Happy vs Unhappy in X2:\n",
      " X2   1   2   3   4  5\n",
      "Y                    \n",
      "0   13  13  19  10  2\n",
      "1   14  21  23   7  4\n"
     ]
    }
   ],
   "source": [
    "#counting the ratings for X2 as well as the number of happy customers vs. unhappy customers\n",
    "\n",
    "ratings_X2 = customers['X2'].value_counts().sort_index()\n",
    "happy_unhappy_X2 = customers.groupby('Y')['X2'].value_counts().unstack().fillna(0)\n",
    "\n",
    "print(\"\\nRatings distribution for X2:\\n\", ratings_X2)\n",
    "print(\"\\nHappy vs Unhappy in X2:\\n\", happy_unhappy_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6cede1e-5880-4ad3-961a-5e83227e9740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings distribution for X3:\n",
      " X3\n",
      "1     7\n",
      "2    14\n",
      "3    55\n",
      "4    33\n",
      "5    17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Happy vs Unhappy in X3:\n",
      " X3  1  2   3   4   5\n",
      "Y                   \n",
      "0   4  7  29  11   6\n",
      "1   3  7  26  22  11\n"
     ]
    }
   ],
   "source": [
    "#counting the ratings for X3 as well as the number of happy customers vs. unhappy customers\n",
    "\n",
    "ratings_X3 = customers['X3'].value_counts().sort_index()\n",
    "happy_unhappy_X3 = customers.groupby('Y')['X3'].value_counts().unstack().fillna(0)\n",
    "\n",
    "print(\"\\nRatings distribution for X3:\\n\", ratings_X3)\n",
    "print(\"\\nHappy vs Unhappy in X3:\\n\", happy_unhappy_X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3ac28dc-841d-4d37-b8a5-0b5ca3f9abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings distribution for X4:\n",
      " X4\n",
      "1     2\n",
      "2     5\n",
      "3    41\n",
      "4    53\n",
      "5    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Happy vs Unhappy in X4:\n",
      " X4    1    2     3     4     5\n",
      "Y                             \n",
      "0   0.0  4.0  20.0  23.0  10.0\n",
      "1   2.0  1.0  21.0  30.0  15.0\n"
     ]
    }
   ],
   "source": [
    "#counting the ratings for X4 as well as the number of happy customers vs. unhappy customers\n",
    "\n",
    "ratings_X4 = customers['X4'].value_counts().sort_index()\n",
    "happy_unhappy_X4 = customers.groupby('Y')['X4'].value_counts().unstack().fillna(0)\n",
    "\n",
    "print(\"\\nRatings distribution for X4:\\n\", ratings_X4)\n",
    "print(\"\\nHappy vs Unhappy in X4:\\n\", happy_unhappy_X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "589bb7d8-baec-41e6-bcfc-b89b5af9ee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings distribution for X5:\n",
      " X5\n",
      "1     7\n",
      "2    16\n",
      "3    22\n",
      "4    50\n",
      "5    31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Happy vs Unhappy in X5:\n",
      " X5  1  2   3   4   5\n",
      "Y                   \n",
      "0   5  9  12  22   9\n",
      "1   2  7  10  28  22\n"
     ]
    }
   ],
   "source": [
    "#counting the ratings for X5 as well as the number of happy customers vs. unhappy customers\n",
    "\n",
    "ratings_X5 = customers['X5'].value_counts().sort_index()\n",
    "happy_unhappy_X5 = customers.groupby('Y')['X5'].value_counts().unstack().fillna(0)\n",
    "\n",
    "print(\"\\nRatings distribution for X5:\\n\", ratings_X5)\n",
    "print(\"\\nHappy vs Unhappy in X5:\\n\", happy_unhappy_X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3aeea3e-50da-4811-be61-9dd6199cbe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings distribution for X6:\n",
      " X6\n",
      "1     1\n",
      "2     1\n",
      "3    20\n",
      "4    47\n",
      "5    57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Happy vs Unhappy in X6:\n",
      " X6    1    2     3     4     5\n",
      "Y                             \n",
      "0   0.0  1.0  14.0  20.0  22.0\n",
      "1   1.0  0.0   6.0  27.0  35.0\n"
     ]
    }
   ],
   "source": [
    "#counting the ratings for X6 as well as the number of happy customers vs. unhappy customers\n",
    "\n",
    "ratings_X6 = customers['X6'].value_counts().sort_index()\n",
    "happy_unhappy_X6 = customers.groupby('Y')['X6'].value_counts().unstack().fillna(0)\n",
    "\n",
    "print(\"\\nRatings distribution for X6:\\n\", ratings_X6)\n",
    "print(\"\\nHappy vs Unhappy in X6:\\n\", happy_unhappy_X6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff414b0-37a6-4f32-b489-6ec0155ded7c",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4c4f73f-1bed-43c0-9bd8-422afa23817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the target variable Y from the predictors X1-X6\n",
    "\n",
    "X = customers[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']]\n",
    "y = customers['Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1aac58f8-4f16-4617-b2fb-b97ac141e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train and validation sets (80%/20% rule)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b915af-9495-4e14-921a-3510fdff2d7f",
   "metadata": {},
   "source": [
    "# Feature Selection by using RFECV with Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c0ad111-2bb5-40f2-85b8-9e69a1f0fea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['X1', 'X2', 'X5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#initializing a logistic regression model\n",
    "\n",
    "estimator = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "\n",
    "#setting up Recursive Feature Elimination with Cross-Validation\n",
    "\n",
    "selector = RFECV(estimator, step=1, cv=5, scoring='accuracy')\n",
    "\n",
    "#fitting the selector to the training data\n",
    "\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "print(\"Selected features:\", X.columns[selector.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f1aac5c-281a-463f-832f-83c994a3bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the dataset to include only the selected features in the previous step\n",
    "\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_valid_selected = selector.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96e656-f548-47f4-bddd-51a6b437a30a",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with GridSearchCV for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a99ce514-8fee-41c5-9f1d-1b9814cb5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#defining the parameter grid for the cross-validation\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  #regularization strength\n",
    "    'penalty': ['l1', 'l2'],       #regularization type\n",
    "}\n",
    "\n",
    "#initializing a new logistic regression model to be tuned through GridSearch\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "\n",
    "#setting up a grid search to find the best hyperparameters using cross-validation\n",
    "\n",
    "grid = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "#fitting the grid search to the training data\n",
    "\n",
    "grid.fit(X_train_selected, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e54d466-124f-4bde-9c40-d5046fcd858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieving the model with the best-found parameters\n",
    "\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bf643b5-81b5-4337-9206-71af240f2f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.65\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.42      0.53        12\n",
      "           1       0.63      0.86      0.73        14\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.67      0.64      0.63        26\n",
      "weighted avg       0.67      0.65      0.63        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#doing the model evaluation on the validation set\n",
    "\n",
    "y_pred = best_model.predict(X_valid_selected)\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27c561b7-e9ff-411c-85c5-7f0dbb524cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1: 0.2466\n",
      "X2: -0.2150\n",
      "X5: 0.1940\n"
     ]
    }
   ],
   "source": [
    "#measuring the feature importance\n",
    "\n",
    "coefficients = best_model.coef_[0]\n",
    "for feature, coef in zip(X.columns[selector.support_], coefficients):\n",
    "    print(f\"{feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d57b40-fa6a-47a6-913a-16cabdab8e04",
   "metadata": {},
   "source": [
    "# Feature Selection by using RFECV with Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ec9d937-67a5-41b0-b22d-4bd1aa0fa0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 4\n",
      "Selected features: ['X1', 'X2', 'X3', 'X5']\n"
     ]
    }
   ],
   "source": [
    "#initializing a random forest model \n",
    "\n",
    "rf_estimator = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#setting up Recursive Feature Elimination with Cross-Validation\n",
    "\n",
    "selector = RFECV(rf_estimator, step=1, cv=5, scoring='accuracy')\n",
    "\n",
    "#fitting the selector to the training data\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features:\", selector.n_features_)\n",
    "print(\"Selected features:\", list(X.columns[selector.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7f16e6f-95e6-456a-9b15-c6abc0936cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the  training and validation sets\n",
    "\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_valid_selected = selector.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a29e1-531c-42c5-b048-3e6318bcfcb6",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning for Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d10a5aa-0ac5-433a-be67-eb3f373f1a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "404 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "136 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\maadm\\Downloads\\anac\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 0.58\n",
      " 0.58 0.6  0.58 0.56 0.56 0.57 0.59 0.58 0.59 0.58 0.59 0.59 0.61 0.6\n",
      " 0.58 0.58 0.59 0.6  0.57 0.58 0.6  0.57 0.58 0.61 0.57 0.59 0.58 0.58\n",
      " 0.6  0.58 0.56 0.56 0.57 0.59 0.58 0.59 0.58 0.59 0.59 0.61 0.6  0.58\n",
      " 0.58 0.59 0.6  0.57 0.58 0.6  0.57 0.58 0.61 0.57 0.59  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan 0.57 0.6  0.59 0.59\n",
      " 0.55 0.55 0.58 0.58 0.57 0.59 0.58 0.6  0.6  0.6  0.59 0.6  0.58 0.59\n",
      " 0.6  0.57 0.57 0.6  0.57 0.57 0.61 0.59 0.59 0.57 0.6  0.59 0.59 0.55\n",
      " 0.55 0.58 0.58 0.57 0.59 0.58 0.6  0.6  0.6  0.59 0.6  0.58 0.59 0.6\n",
      " 0.57 0.57 0.6  0.57 0.57 0.61 0.59 0.59  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan 0.56 0.57 0.59 0.58 0.55 0.56 0.57\n",
      " 0.59 0.58 0.59 0.58 0.59 0.59 0.61 0.6  0.58 0.58 0.59 0.6  0.57 0.58\n",
      " 0.6  0.57 0.58 0.61 0.57 0.59 0.56 0.57 0.59 0.58 0.55 0.56 0.57 0.59\n",
      " 0.58 0.59 0.58 0.59 0.59 0.61 0.6  0.58 0.58 0.59 0.6  0.57 0.58 0.6\n",
      " 0.57 0.58 0.61 0.57 0.59  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan 0.58 0.58 0.6  0.58 0.56 0.56 0.57 0.59 0.58 0.59\n",
      " 0.58 0.59 0.59 0.61 0.6  0.58 0.58 0.59 0.6  0.57 0.58 0.6  0.57 0.58\n",
      " 0.61 0.57 0.59 0.58 0.58 0.6  0.58 0.56 0.56 0.57 0.59 0.58 0.59 0.58\n",
      " 0.59 0.59 0.61 0.6  0.58 0.58 0.59 0.6  0.57 0.58 0.6  0.57 0.58 0.61\n",
      " 0.57 0.59]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=200, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=200, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 10, 20],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the parameter grid for the cross-validation\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "#initializing a new random forest model\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#setting up a grid search to find the best hyperparameters using cross-validation\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "#fitting the grid search to the training data\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "#print(\"Best parameters found:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea25ab60-2cd9-46cb-a0cb-71d053aced49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieving the model with the best-found parameters\n",
    "\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "faecfeb2-eaf4-4d31-8333-7b2f70b12d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.69\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        12\n",
      "           1       0.71      0.71      0.71        14\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.69      0.69      0.69        26\n",
      "weighted avg       0.69      0.69      0.69        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#doing the model evaluation on the validation set\n",
    "\n",
    "y_pred = best_rf.predict(X_valid_selected)\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62b29e-76cb-40f3-bb8a-1a641cc01892",
   "metadata": {},
   "source": [
    "# Feature Scaling for SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b5a7d914-8244-45dc-a22e-f5ad69db77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing an instance of the Standard Scaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fitting the Standard Scaler to the data\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "045ca564-cb28-408c-afee-bb37c88b1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting dataset into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65131095-a2c7-4444-acd9-6d2506beb44a",
   "metadata": {},
   "source": [
    "# Feature selection by using RFECV with SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d55112f-58db-4f25-8c83-f2aa4d0b784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 1\n",
      "Selected features: ['X1']\n"
     ]
    }
   ],
   "source": [
    "#initializing an SVC model \n",
    "\n",
    "svc_estimator = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "#setting up Recursive Feature Elimination with Cross-Validation\n",
    "\n",
    "selector = RFECV(svc_estimator, step=1, cv=5, scoring='accuracy')\n",
    "\n",
    "#fitting the selector to the training data\n",
    "\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features:\", selector.n_features_)\n",
    "print(\"Selected features:\", list(X.columns[selector.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e297da50-1588-46d0-8102-4f24076753f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the training and validation sets\n",
    "\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_valid_selected = selector.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674c0f7-9538-4e61-8bd5-34afdc11c893",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning for SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5183adb-fb2c-4bc8-9a74-c9b6614ede88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "#defining the parameter grid for the cross-validation\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']  #only relevant for 'rbf' kernel\n",
    "}\n",
    "\n",
    "#initializing a new SVC model\n",
    "\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "#initializing GridSearchCV to search for the best hyperparameters\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "#fitting the GridSearchCV to the training data \n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cee3b56-0254-43b1-ba45-5faa485f51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieving the model with the best-found parameters\n",
    "\n",
    "best_svc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc619476-edcb-4b97-ba4c-de62f1a0d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.73\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70        12\n",
      "           1       0.73      0.79      0.76        14\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.73      0.73      0.73        26\n",
      "weighted avg       0.73      0.73      0.73        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#doing the model evaluation on the validation set\n",
    "\n",
    "y_pred = best_svc.predict(X_valid_selected)\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53acb5-4c2b-4a20-b4ba-477614375c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a86785d1-856e-48f7-ad58-fb92ae222d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef964606-a668-4bd1-b1c7-1cd834c964c8",
   "metadata": {},
   "source": [
    "# Feature Selection for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3361cfa9-234c-4d79-9657-79e41e2c2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiating an instance of the XGBoost Model\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# fittting the model to the training data\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#fitting the selector to the training data\n",
    "\n",
    "selector = SelectFromModel(model, prefit=True)\n",
    "\n",
    "#transforming the training and validation datas to retain the selected features\n",
    "\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_val_selected = selector.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144209e8-5a73-4581-8414-68c3779cde97",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Optuna for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d7a41384-2ce2-40c8-8b9d-846e18f96671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-03 16:57:09,418] A new study created in memory with name: no-name-32f71a5b-41a2-45a3-b7d1-98b771f3239d\n",
      "[I 2025-08-03 16:57:09,490] Trial 0 finished with value: 0.7307692307692307 and parameters: {'max_depth': 4, 'learning_rate': 0.17055988994462612, 'n_estimators': 135, 'subsample': 0.7724094686835079, 'colsample_bytree': 0.5919239736855275, 'gamma': 2.939325967013593}. Best is trial 0 with value: 0.7307692307692307.\n",
      "[I 2025-08-03 16:57:09,707] Trial 1 finished with value: 0.7307692307692307 and parameters: {'max_depth': 6, 'learning_rate': 0.1224787394323923, 'n_estimators': 607, 'subsample': 0.5559829914214132, 'colsample_bytree': 0.7692054272588472, 'gamma': 2.805719929723669}. Best is trial 0 with value: 0.7307692307692307.\n",
      "[I 2025-08-03 16:57:09,808] Trial 2 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.26132027626544296, 'n_estimators': 267, 'subsample': 0.9020180733419183, 'colsample_bytree': 0.8092376619925836, 'gamma': 0.662107282061597}. Best is trial 0 with value: 0.7307692307692307.\n",
      "[I 2025-08-03 16:57:09,962] Trial 3 finished with value: 0.7307692307692307 and parameters: {'max_depth': 4, 'learning_rate': 0.22357255688959504, 'n_estimators': 455, 'subsample': 0.6341946322867954, 'colsample_bytree': 0.7553665068744104, 'gamma': 1.7647513368140628}. Best is trial 0 with value: 0.7307692307692307.\n",
      "[I 2025-08-03 16:57:10,191] Trial 4 finished with value: 0.7307692307692307 and parameters: {'max_depth': 5, 'learning_rate': 0.09032802165360393, 'n_estimators': 672, 'subsample': 0.7700836926249621, 'colsample_bytree': 0.7782933024518346, 'gamma': 4.450559267816035}. Best is trial 0 with value: 0.7307692307692307.\n",
      "[I 2025-08-03 16:57:10,285] Trial 5 finished with value: 0.7307692307692307 and parameters: {'max_depth': 7, 'learning_rate': 0.11556887883528917, 'n_estimators': 261, 'subsample': 0.8232313810752616, 'colsample_bytree': 0.8100496582352007, 'gamma': 1.5667152509596822}. Best is trial 0 with value: 0.7307692307692307.\n",
      "[I 2025-08-03 16:57:10,520] Trial 6 finished with value: 0.7307692307692307 and parameters: {'max_depth': 6, 'learning_rate': 0.2248951456550249, 'n_estimators': 668, 'subsample': 0.8735420630089599, 'colsample_bytree': 0.8502948276170748, 'gamma': 3.506987233844376}. Best is trial 0 with value: 0.7307692307692307.\n",
      "[I 2025-08-03 16:57:10,865] Trial 7 finished with value: 0.7692307692307693 and parameters: {'max_depth': 3, 'learning_rate': 0.18990398767656982, 'n_estimators': 855, 'subsample': 0.8282106342366561, 'colsample_bytree': 0.9724452860337269, 'gamma': 0.43196934881542415}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:11,104] Trial 8 finished with value: 0.7307692307692307 and parameters: {'max_depth': 3, 'learning_rate': 0.16731645083746619, 'n_estimators': 643, 'subsample': 0.5393999778139178, 'colsample_bytree': 0.6284835907225365, 'gamma': 3.5074661126323523}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:11,228] Trial 9 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.29820303713956137, 'n_estimators': 302, 'subsample': 0.5345618905886094, 'colsample_bytree': 0.8300449462708619, 'gamma': 1.1236803585646638}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:11,696] Trial 10 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.024138498831475785, 'n_estimators': 913, 'subsample': 0.9837621620556616, 'colsample_bytree': 0.9350928290600077, 'gamma': 0.0631958279960747}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:12,121] Trial 11 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.28547675494711855, 'n_estimators': 967, 'subsample': 0.6528777643036819, 'colsample_bytree': 0.9764947850345492, 'gamma': 1.0776255676225057}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:12,630] Trial 12 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.2985471988946884, 'n_estimators': 809, 'subsample': 0.6827458962603545, 'colsample_bytree': 0.899511575379669, 'gamma': 0.10504274132527913}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:12,845] Trial 13 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.221309984451445, 'n_estimators': 421, 'subsample': 0.5050209120864454, 'colsample_bytree': 0.689435407953427, 'gamma': 1.8975165586687404}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:13,040] Trial 14 finished with value: 0.7307692307692307 and parameters: {'max_depth': 3, 'learning_rate': 0.030269511655748413, 'n_estimators': 421, 'subsample': 0.696546796191443, 'colsample_bytree': 0.5031445871744641, 'gamma': 0.8188217659367407}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:13,379] Trial 15 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.19726123425032344, 'n_estimators': 821, 'subsample': 0.5893368269558046, 'colsample_bytree': 0.9782840167231444, 'gamma': 1.0878163197834967}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:13,523] Trial 16 finished with value: 0.7307692307692307 and parameters: {'max_depth': 7, 'learning_rate': 0.2515588578721951, 'n_estimators': 284, 'subsample': 0.9444081858007882, 'colsample_bytree': 0.8781449428194615, 'gamma': 2.1962785438597123}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:13,639] Trial 17 finished with value: 0.7307692307692307 and parameters: {'max_depth': 5, 'learning_rate': 0.07072765840229778, 'n_estimators': 147, 'subsample': 0.8302924725396909, 'colsample_bytree': 0.999838621119285, 'gamma': 0.473540005943222}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:13,880] Trial 18 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.13755085904873998, 'n_estimators': 510, 'subsample': 0.7262511678175716, 'colsample_bytree': 0.93300196454199, 'gamma': 1.1591942170072522}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:14,209] Trial 19 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.19024979865308098, 'n_estimators': 794, 'subsample': 0.8058826430814652, 'colsample_bytree': 0.703523095144286, 'gamma': 4.897083723434581}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:14,374] Trial 20 finished with value: 0.7307692307692307 and parameters: {'max_depth': 5, 'learning_rate': 0.2593296412151509, 'n_estimators': 304, 'subsample': 0.6111159737160758, 'colsample_bytree': 0.8437006088777309, 'gamma': 1.60657857377515}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:14,826] Trial 21 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.011218700060192932, 'n_estimators': 973, 'subsample': 0.9957783610899908, 'colsample_bytree': 0.9260892211783636, 'gamma': 0.20799758232979948}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:15,340] Trial 22 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.06543403801938233, 'n_estimators': 888, 'subsample': 0.9680078458840606, 'colsample_bytree': 0.9406542943039925, 'gamma': 0.025583179702756587}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:15,659] Trial 23 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.1494042802339204, 'n_estimators': 733, 'subsample': 0.9013768768241437, 'colsample_bytree': 0.8805917508220543, 'gamma': 0.5463354710992393}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:16,020] Trial 24 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.061942638889704305, 'n_estimators': 905, 'subsample': 0.8631133299829411, 'colsample_bytree': 0.9579839005420879, 'gamma': 1.2665351052150362}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:16,234] Trial 25 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.11073367339417964, 'n_estimators': 549, 'subsample': 0.9482006360271956, 'colsample_bytree': 0.8987619287742192, 'gamma': 0.40473161781494726}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:16,556] Trial 26 finished with value: 0.7307692307692307 and parameters: {'max_depth': 7, 'learning_rate': 0.20045296943064406, 'n_estimators': 887, 'subsample': 0.7366917935878803, 'colsample_bytree': 0.838040017742792, 'gamma': 0.8206681074656565}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:16,986] Trial 27 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.033084004239170614, 'n_estimators': 730, 'subsample': 0.922257485637952, 'colsample_bytree': 0.9141737991923639, 'gamma': 0.005148304747239596}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:17,249] Trial 28 finished with value: 0.7307692307692307 and parameters: {'max_depth': 4, 'learning_rate': 0.23958114547855203, 'n_estimators': 756, 'subsample': 0.9883207181726466, 'colsample_bytree': 0.863508861038863, 'gamma': 2.3167653714740597}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:17,347] Trial 29 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.17247011049561164, 'n_estimators': 157, 'subsample': 0.7948816407263286, 'colsample_bytree': 0.9936527019454375, 'gamma': 1.4549434735612665}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:17,734] Trial 30 finished with value: 0.7692307692307693 and parameters: {'max_depth': 6, 'learning_rate': 0.2823795863452827, 'n_estimators': 984, 'subsample': 0.760566955793385, 'colsample_bytree': 0.7101296899457779, 'gamma': 0.8726632305248583}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:18,238] Trial 31 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.2823836697955504, 'n_estimators': 999, 'subsample': 0.6444059651343016, 'colsample_bytree': 0.9608086544458971, 'gamma': 0.3857183128560014}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:18,651] Trial 32 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.29895442048879806, 'n_estimators': 928, 'subsample': 0.5765460439698173, 'colsample_bytree': 0.9596077726130939, 'gamma': 1.0265880034064803}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:19,038] Trial 33 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.27550078105335024, 'n_estimators': 837, 'subsample': 0.5134275157076653, 'colsample_bytree': 0.8022979665572165, 'gamma': 2.6317220606829577}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:19,537] Trial 34 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.2420716986714264, 'n_estimators': 938, 'subsample': 0.6659074891338113, 'colsample_bytree': 0.9657785816288036, 'gamma': 0.6471632768073181}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:19,719] Trial 35 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.2685597054812916, 'n_estimators': 342, 'subsample': 0.7165334238113205, 'colsample_bytree': 0.9296285723207292, 'gamma': 2.0309928166209223}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:20,075] Trial 36 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.09276903542724863, 'n_estimators': 854, 'subsample': 0.6339942211295272, 'colsample_bytree': 0.9993615797910358, 'gamma': 3.0538508726816236}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:20,391] Trial 37 finished with value: 0.7307692307692307 and parameters: {'max_depth': 6, 'learning_rate': 0.21110495814030145, 'n_estimators': 615, 'subsample': 0.5502061747445837, 'colsample_bytree': 0.8868073265465638, 'gamma': 1.4085405048437853}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:20,533] Trial 38 finished with value: 0.7692307692307693 and parameters: {'max_depth': 3, 'learning_rate': 0.1730852265950903, 'n_estimators': 222, 'subsample': 0.8634624440702692, 'colsample_bytree': 0.7886661261691956, 'gamma': 0.3736873239567612}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:21,063] Trial 39 finished with value: 0.7692307692307693 and parameters: {'max_depth': 4, 'learning_rate': 0.13802974986639677, 'n_estimators': 947, 'subsample': 0.5707492398913855, 'colsample_bytree': 0.7319116970680213, 'gamma': 0.6722327221635805}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:21,489] Trial 40 finished with value: 0.7307692307692307 and parameters: {'max_depth': 7, 'learning_rate': 0.23365252861712865, 'n_estimators': 767, 'subsample': 0.6127806426509128, 'colsample_bytree': 0.8359659964741257, 'gamma': 1.724284113021658}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:21,761] Trial 41 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.12955603676409946, 'n_estimators': 513, 'subsample': 0.71204650606183, 'colsample_bytree': 0.9447492253699369, 'gamma': 1.1957213715358572}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:22,039] Trial 42 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.09417045096473378, 'n_estimators': 486, 'subsample': 0.7768760893995881, 'colsample_bytree': 0.9141436767777161, 'gamma': 1.000802588146637}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:22,371] Trial 43 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.15578328846432343, 'n_estimators': 694, 'subsample': 0.6723561712227692, 'colsample_bytree': 0.641860961247207, 'gamma': 1.2398533871377033}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:22,559] Trial 44 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.29405324067082517, 'n_estimators': 369, 'subsample': 0.7350378664455116, 'colsample_bytree': 0.9729566012401366, 'gamma': 3.843368805361628}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:22,918] Trial 45 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.25381744354408964, 'n_estimators': 593, 'subsample': 0.839631691270146, 'colsample_bytree': 0.8165209978234839, 'gamma': 0.22728154921991928}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:23,087] Trial 46 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.036913128835040554, 'n_estimators': 211, 'subsample': 0.5205214436680837, 'colsample_bytree': 0.9062677273638005, 'gamma': 0.7288041210633094}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:23,529] Trial 47 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.10811159116509547, 'n_estimators': 865, 'subsample': 0.8947396787543431, 'colsample_bytree': 0.9398705869558801, 'gamma': 1.9342611626442507}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:23,797] Trial 48 finished with value: 0.7307692307692307 and parameters: {'max_depth': 5, 'learning_rate': 0.07563038752298573, 'n_estimators': 400, 'subsample': 0.7000826228724051, 'colsample_bytree': 0.8747397398485832, 'gamma': 0.896088672982656}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:23,904] Trial 49 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.05205902849068108, 'n_estimators': 100, 'subsample': 0.6504980944467, 'colsample_bytree': 0.7618142965119149, 'gamma': 0.312094483371537}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:24,182] Trial 50 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.014987357624474191, 'n_estimators': 457, 'subsample': 0.8107183165581006, 'colsample_bytree': 0.5121571961889282, 'gamma': 1.4465761990334847}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:24,774] Trial 51 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.0517922426845095, 'n_estimators': 897, 'subsample': 0.9470694928560803, 'colsample_bytree': 0.9358001804787408, 'gamma': 0.07884578699276834}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:25,200] Trial 52 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.04492019396258258, 'n_estimators': 803, 'subsample': 0.9721178988397338, 'colsample_bytree': 0.9813014056918112, 'gamma': 0.5480773734669557}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:25,756] Trial 53 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.18655321123679708, 'n_estimators': 957, 'subsample': 0.9622234845024246, 'colsample_bytree': 0.9490923517240355, 'gamma': 0.10533220576575149}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:26,308] Trial 54 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.02120407157160928, 'n_estimators': 919, 'subsample': 0.7782353458970275, 'colsample_bytree': 0.977844534395584, 'gamma': 0.5143475489408413}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:26,824] Trial 55 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.07506803383561984, 'n_estimators': 863, 'subsample': 0.9257815035101954, 'colsample_bytree': 0.9199409132721454, 'gamma': 0.27858775931126994}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:27,411] Trial 56 finished with value: 0.7692307692307693 and parameters: {'max_depth': 8, 'learning_rate': 0.2187430004165711, 'n_estimators': 563, 'subsample': 0.8818381048164348, 'colsample_bytree': 0.8548827329804289, 'gamma': 0.017592073569770893}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:27,755] Trial 57 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.12443223518213051, 'n_estimators': 648, 'subsample': 0.9264200985310789, 'colsample_bytree': 0.8956651605725909, 'gamma': 1.0934760297439738}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:28,122] Trial 58 finished with value: 0.7307692307692307 and parameters: {'max_depth': 5, 'learning_rate': 0.10277730521163479, 'n_estimators': 698, 'subsample': 0.9799666847122684, 'colsample_bytree': 0.9807894981744119, 'gamma': 1.7440324619336465}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:28,599] Trial 59 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.06479507331308265, 'n_estimators': 890, 'subsample': 0.7443835855292662, 'colsample_bytree': 0.9280372492623392, 'gamma': 0.7355753076309407}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:29,201] Trial 60 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.14826893069447028, 'n_estimators': 789, 'subsample': 0.6052671223462956, 'colsample_bytree': 0.8679523812793501, 'gamma': 0.2239624115991195}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:29,787] Trial 61 finished with value: 0.7692307692307693 and parameters: {'max_depth': 6, 'learning_rate': 0.28846928875460437, 'n_estimators': 991, 'subsample': 0.7572949192448294, 'colsample_bytree': 0.7324079948194478, 'gamma': 0.9229675644840247}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:30,308] Trial 62 finished with value: 0.7307692307692307 and parameters: {'max_depth': 3, 'learning_rate': 0.26320496977493224, 'n_estimators': 970, 'subsample': 0.8508625270264519, 'colsample_bytree': 0.6723058223260429, 'gamma': 0.5546092929144961}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:30,753] Trial 63 finished with value: 0.7307692307692307 and parameters: {'max_depth': 7, 'learning_rate': 0.2744677728795878, 'n_estimators': 831, 'subsample': 0.8007438631651704, 'colsample_bytree': 0.7190545333436608, 'gamma': 0.8472203791824369}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:31,298] Trial 64 finished with value: 0.7307692307692307 and parameters: {'max_depth': 6, 'learning_rate': 0.28365947894940385, 'n_estimators': 928, 'subsample': 0.7615879341084697, 'colsample_bytree': 0.6763318310434548, 'gamma': 1.184558731087171}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:31,922] Trial 65 finished with value: 0.7692307692307693 and parameters: {'max_depth': 5, 'learning_rate': 0.24613046603956004, 'n_estimators': 995, 'subsample': 0.7261080140896715, 'colsample_bytree': 0.9530903519050168, 'gamma': 0.48080167665448276}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:32,372] Trial 66 finished with value: 0.7692307692307693 and parameters: {'max_depth': 3, 'learning_rate': 0.29909339616313796, 'n_estimators': 865, 'subsample': 0.6835498590651099, 'colsample_bytree': 0.7768057513323005, 'gamma': 1.3444953314393213}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:32,554] Trial 67 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.2686982215475981, 'n_estimators': 309, 'subsample': 0.9957028140426407, 'colsample_bytree': 0.8246885319571642, 'gamma': 0.7098132134792117}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:33,013] Trial 68 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.23080993242017442, 'n_estimators': 965, 'subsample': 0.8224636717848988, 'colsample_bytree': 0.9872786189597501, 'gamma': 1.026684614756943}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:33,487] Trial 69 finished with value: 0.7307692307692307 and parameters: {'max_depth': 4, 'learning_rate': 0.1815898766837892, 'n_estimators': 916, 'subsample': 0.526839635646312, 'colsample_bytree': 0.5983966512571637, 'gamma': 1.6282511470443348}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:34,102] Trial 70 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.08408644304099992, 'n_estimators': 882, 'subsample': 0.7846159483308249, 'colsample_bytree': 0.8936256702045294, 'gamma': 0.16005810089425831}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:34,728] Trial 71 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.28155139719594613, 'n_estimators': 998, 'subsample': 0.6447022590019685, 'colsample_bytree': 0.9641633554918846, 'gamma': 0.35056910539804076}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:35,354] Trial 72 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.2845191421036603, 'n_estimators': 945, 'subsample': 0.6237571744334954, 'colsample_bytree': 0.9602053310030617, 'gamma': 0.3892061772503508}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:35,937] Trial 73 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.29102862927738216, 'n_estimators': 974, 'subsample': 0.5940232977857716, 'colsample_bytree': 0.9411548414687366, 'gamma': 0.6153608172451122}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:36,389] Trial 74 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.25785979417044214, 'n_estimators': 839, 'subsample': 0.7042277612376471, 'colsample_bytree': 0.9127779085495893, 'gamma': 0.8329138490520052}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:36,859] Trial 75 finished with value: 0.7307692307692307 and parameters: {'max_depth': 4, 'learning_rate': 0.274508428080496, 'n_estimators': 907, 'subsample': 0.5657474575385482, 'colsample_bytree': 0.9982655999707579, 'gamma': 2.9708841569050675}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:37,337] Trial 76 finished with value: 0.7307692307692307 and parameters: {'max_depth': 7, 'learning_rate': 0.2085035165791485, 'n_estimators': 943, 'subsample': 0.6860444732010513, 'colsample_bytree': 0.9695428741565536, 'gamma': 4.803448258100887}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:37,509] Trial 77 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.023549761970330322, 'n_estimators': 191, 'subsample': 0.6499510017367289, 'colsample_bytree': 0.925164711427798, 'gamma': 0.4087553846157822}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:38,045] Trial 78 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.16026623003843918, 'n_estimators': 979, 'subsample': 0.7208095886439002, 'colsample_bytree': 0.7441474010827867, 'gamma': 3.3399646982327993}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:38,234] Trial 79 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.26887061087356784, 'n_estimators': 271, 'subsample': 0.6662995032924133, 'colsample_bytree': 0.7928057878341653, 'gamma': 2.2905141154189286}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:38,717] Trial 80 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.2771734595189134, 'n_estimators': 521, 'subsample': 0.5520011117364072, 'colsample_bytree': 0.9507199592981702, 'gamma': 0.14299507212955173}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:39,189] Trial 81 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.29375374496396783, 'n_estimators': 819, 'subsample': 0.5122895789993355, 'colsample_bytree': 0.80143840905455, 'gamma': 2.613541720573511}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:39,699] Trial 82 finished with value: 0.7692307692307693 and parameters: {'max_depth': 10, 'learning_rate': 0.2641938606904407, 'n_estimators': 882, 'subsample': 0.5015945172321824, 'colsample_bytree': 0.6876570644899014, 'gamma': 2.711863744808205}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:40,483] Trial 83 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.24928416499353007, 'n_estimators': 758, 'subsample': 0.5295530517017972, 'colsample_bytree': 0.7567723282691108, 'gamma': 0.0028382049617483793}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:40,871] Trial 84 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.13623757255962787, 'n_estimators': 848, 'subsample': 0.9553717385222986, 'colsample_bytree': 0.906271154082133, 'gamma': 1.0808781419499183}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:41,276] Trial 85 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.28141902624803733, 'n_estimators': 782, 'subsample': 0.587058663781873, 'colsample_bytree': 0.7116973474082418, 'gamma': 2.5321376630097365}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:41,663] Trial 86 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.2558293838732991, 'n_estimators': 734, 'subsample': 0.5339856263932009, 'colsample_bytree': 0.9379096491478373, 'gamma': 2.184781897429017}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:42,229] Trial 87 finished with value: 0.7307692307692307 and parameters: {'max_depth': 8, 'learning_rate': 0.03908193004087245, 'n_estimators': 954, 'subsample': 0.5451167163167384, 'colsample_bytree': 0.9908496217509701, 'gamma': 1.5284312642415483}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:42,726] Trial 88 finished with value: 0.7307692307692307 and parameters: {'max_depth': 9, 'learning_rate': 0.11696657918423628, 'n_estimators': 928, 'subsample': 0.9143741558331546, 'colsample_bytree': 0.8476701962084239, 'gamma': 3.1052256486152756}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:43,427] Trial 89 finished with value: 0.7307692307692307 and parameters: {'max_depth': 10, 'learning_rate': 0.2891520309064195, 'n_estimators': 902, 'subsample': 0.6226630855823364, 'colsample_bytree': 0.8236875091456918, 'gamma': 0.2567975175993636}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:43,718] Trial 90 finished with value: 0.7307692307692307 and parameters: {'max_depth': 7, 'learning_rate': 0.20111260797306557, 'n_estimators': 450, 'subsample': 0.9674710747276275, 'colsample_bytree': 0.6467213115007466, 'gamma': 0.7455288858799093}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:43,910] Trial 91 finished with value: 0.7692307692307693 and parameters: {'max_depth': 3, 'learning_rate': 0.17284421439481287, 'n_estimators': 234, 'subsample': 0.8651307817851666, 'colsample_bytree': 0.7969770515224062, 'gamma': 0.4071651875920389}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:44,030] Trial 92 finished with value: 0.7307692307692307 and parameters: {'max_depth': 3, 'learning_rate': 0.1640203816812941, 'n_estimators': 116, 'subsample': 0.8165693534333366, 'colsample_bytree': 0.7735247515002425, 'gamma': 0.6053987111874446}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:44,242] Trial 93 finished with value: 0.7307692307692307 and parameters: {'max_depth': 4, 'learning_rate': 0.1471814013649615, 'n_estimators': 304, 'subsample': 0.8857326364465248, 'colsample_bytree': 0.7831105191779222, 'gamma': 1.307561634402139}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:44,444] Trial 94 finished with value: 0.7692307692307693 and parameters: {'max_depth': 3, 'learning_rate': 0.17903507168503507, 'n_estimators': 230, 'subsample': 0.8426248713914295, 'colsample_bytree': 0.8840118602404485, 'gamma': 0.32075495937070525}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:44,593] Trial 95 finished with value: 0.7307692307692307 and parameters: {'max_depth': 4, 'learning_rate': 0.19134859136885787, 'n_estimators': 160, 'subsample': 0.7892142942042262, 'colsample_bytree': 0.9762241668870003, 'gamma': 0.9794413938820652}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:44,857] Trial 96 finished with value: 0.7307692307692307 and parameters: {'max_depth': 3, 'learning_rate': 0.2970668684770494, 'n_estimators': 392, 'subsample': 0.7629756912947406, 'colsample_bytree': 0.7427860030413976, 'gamma': 1.1777898904437334}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:45,040] Trial 97 finished with value: 0.7692307692307693 and parameters: {'max_depth': 6, 'learning_rate': 0.0561794367907497, 'n_estimators': 180, 'subsample': 0.7470323973524988, 'colsample_bytree': 0.8332866159468921, 'gamma': 0.46643616457887765}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:45,265] Trial 98 finished with value: 0.7307692307692307 and parameters: {'max_depth': 5, 'learning_rate': 0.09871302453914055, 'n_estimators': 326, 'subsample': 0.908475927424726, 'colsample_bytree': 0.7862433182602293, 'gamma': 3.883513246264556}. Best is trial 7 with value: 0.7692307692307693.\n",
      "[I 2025-08-03 16:57:45,687] Trial 99 finished with value: 0.7692307692307693 and parameters: {'max_depth': 9, 'learning_rate': 0.27276529890832796, 'n_estimators': 615, 'subsample': 0.9418441588833102, 'colsample_bytree': 0.8050303415487707, 'gamma': 0.1366639395752308}. Best is trial 7 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Accuracy: 0.7692307692307693\n",
      "  Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.18990398767656982, 'n_estimators': 855, 'subsample': 0.8282106342366561, 'colsample_bytree': 0.9724452860337269, 'gamma': 0.43196934881542415}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):       #defining an objective function for the Optuna study\n",
    "    param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5)\n",
    "    }              #setting up a dictionary of hyperparameters to optimize\n",
    "\n",
    "#createing another instance of the XGBClassifier using the hyperparameters in param \n",
    "#training it on the selected features of the training set and then predicting the validation set\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    preds = model.predict(X_val_selected)\n",
    "\n",
    "#returning the accuracy of the model predictions on the validation set    \n",
    "    accuracy = accuracy_score(y_valid, preds)\n",
    "    return accuracy\n",
    "\n",
    "#creating an Optuna study object that aims to maximize the objective function to find the hyperparameter set that yields the highest accuracy\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "#running the optimization process for 100 trials to explore the different hyperparameter combinations\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "#returning the best trial results by displaying the highest accuracy and the corresponding set of hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f'  Accuracy: {trial.value}')\n",
    "print(\"  Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a632757-a419-4036-8af5-f275309541b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "#retrieving the best hyperparameters from the study and initializing a new XGBoost model with these parameters\n",
    "best_params = trial.params\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "#training the new model on the selected features of the training set and predicting on the validation set\n",
    "best_model.fit(X_train_selected, y_train)\n",
    "final_predictions = best_model.predict(X_val_selected)\n",
    "\n",
    "#calculating the final accuracy of the new model\n",
    "final_accuracy = accuracy_score(y_valid, final_predictions)\n",
    "print(f'Final Accuracy: {final_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ac47e-8096-4ddb-8e24-b634cafd2aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e3986-8b07-4646-9d6e-0b5ac829259c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d490ad-5002-4b9c-a27b-db35b4ac7568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf666f9-7c95-4f5a-9698-eb793c096f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
